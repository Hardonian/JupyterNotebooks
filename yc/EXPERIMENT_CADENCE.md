# Experiment Cadence & Review Process - Agent Factory

**For:** Techstars, Lean Startup Methodology, Data-Driven Iteration  
**Last Updated:** 2024-01-XX

---

## Overview

This document defines our experiment cadence, review process, and hypothesis-testing rhythm. Regular experimentation and learning are core to our product development and growth strategy.

---

## Experiment Cadence

### Weekly Experiment Reviews
- **Frequency:** Every Monday, 1 hour
- **Participants:** Founders, key team members
- **Format:** Review previous week's experiments, plan next week's experiments

### Monthly Hypothesis Review
- **Frequency:** First Monday of each month, 2 hours
- **Participants:** Full team
- **Format:** Review all hypotheses, update status, identify pivots

### Quarterly Strategy Review
- **Frequency:** First Monday of each quarter, half day
- **Participants:** Full team + advisors
- **Format:** Major strategy review, roadmap updates, pivot decisions

---

## Experiment Review Process

### Weekly Review Agenda

**1. Review Previous Week's Experiments (20 min)**
- What experiments ran?
- What were the results?
- What did we learn?
- Update hypothesis status

**2. Identify Blockers & Questions (10 min)**
- What's blocking progress?
- What questions need answers?
- What data is missing?

**3. Plan Next Week's Experiments (20 min)**
- What's the smallest next experiment?
- What hypothesis does it test?
- What's the success criteria?
- Who owns it?

**4. Update Metrics Dashboard (10 min)**
- Review key metrics
- Identify trends
- Flag anomalies

---

## Experiment Template

See `/yc/EXPERIMENT_TEMPLATE.md` for detailed template.

**Quick Format:**
1. **Hypothesis:** What are we testing?
2. **Experiment:** How are we testing it?
3. **Metrics:** What are we measuring?
4. **Success Criteria:** What defines success?
5. **Timeline:** How long?
6. **Results:** What happened?
7. **Learnings:** What did we learn?
8. **Next Steps:** What's next?

---

## Hypothesis Testing Framework

### Hypothesis States
- **Untested:** Hypothesis not yet tested
- **Testing:** Experiment in progress
- **Validated:** Evidence supports hypothesis
- **Invalidated:** Evidence contradicts hypothesis
- **Pivoting:** Hypothesis invalidated, exploring alternatives

### Hypothesis Review Questions
1. **Status:** What's the current state?
2. **Evidence:** What evidence do we have?
3. **Confidence:** How confident are we? (1-10)
4. **Next Test:** What's the next experiment?
5. **Pivot Risk:** Should we pivot?

---

## Experiment Types

### 1. Problem Validation
- **Purpose:** Validate that the problem exists
- **Methods:** User interviews, surveys, landing page tests
- **Frequency:** Early stage, monthly

### 2. Solution Validation
- **Purpose:** Validate that solution solves the problem
- **Methods:** Concierge tests, MVP usage, time-to-production metrics
- **Frequency:** Early stage, bi-weekly

### 3. Customer Validation
- **Purpose:** Validate customer segments and willingness to pay
- **Methods:** Segment analysis, pricing surveys, conversion data
- **Frequency:** Early stage, monthly

### 4. Feature Validation
- **Purpose:** Validate that features drive value
- **Methods:** Usage metrics, satisfaction surveys, A/B tests
- **Frequency:** Ongoing, weekly

### 5. Growth Validation
- **Purpose:** Validate growth channels and mechanisms
- **Methods:** Channel performance, viral coefficient, network effects
- **Frequency:** Growth stage, weekly

---

## Experiment Tracking

### Experiment Log
Track all experiments in `/yc/EXPERIMENTS_LOG.md`:
- Experiment ID
- Hypothesis tested
- Start date / End date
- Results
- Status (Running / Completed / Cancelled)
- Learnings

### Hypothesis Status
Track hypothesis status in `/yc/HYPOTHESES.md`:
- Current state
- Evidence
- Confidence level
- Next experiment

### Metrics Dashboard
Track metrics in `/yc/TRACTION_SNAPSHOT.md`:
- User metrics
- Revenue metrics
- Growth metrics
- Product metrics

---

## Weekly Experiment Schedule

### Week 1: Problem Validation
- **Experiment:** User interviews (5 developers)
- **Hypothesis:** Developers struggle with infrastructure
- **Metric:** % confirming problem, pain point frequency

### Week 2: Solution Validation
- **Experiment:** Concierge test (help 3 users build agents)
- **Hypothesis:** Agent Factory reduces time to production
- **Metric:** Time saved, satisfaction rating

### Week 3: Customer Validation
- **Experiment:** Pricing survey (20 potential customers)
- **Hypothesis:** Developers will pay $49-199/mo
- **Metric:** Willingness to pay by segment

### Week 4: Growth Validation
- **Experiment:** Landing page test (SEO content)
- **Hypothesis:** SEO drives organic signups
- **Metric:** Signup rate from organic traffic

---

## Monthly Hypothesis Review

### Review Process
1. **Status Check:** Review all hypotheses
2. **Evidence Review:** What evidence do we have?
3. **Confidence Assessment:** Rate confidence (1-10)
4. **Pivot Analysis:** Should we pivot?
5. **Next Quarter Planning:** What to test next?

### Hypothesis Categories
- **Problem Hypotheses:** Is the problem real?
- **Customer Hypotheses:** Who are our customers?
- **Solution Hypotheses:** Does our solution work?
- **Revenue Hypotheses:** Will they pay?
- **Growth Hypotheses:** How do we grow?

---

## Pivot Decision Framework

### Pivot Triggers
See `/yc/PIVOT_CRITERIA.md` for detailed triggers.

**Key Triggers:**
- <1% signup rate after 1000 visitors (problem invalidated)
- <5% conversion rate from free to paid (customer/revenue invalidated)
- <50% satisfaction rating (solution invalidated)
- <1.0 viral coefficient (growth invalidated)

### Pivot Process
1. **Identify:** Hypothesis invalidated
2. **Analyze:** Why did it fail?
3. **Hypothesize:** New hypothesis
4. **Test:** New experiment
5. **Document:** Update learnings

---

## Experiment Tools & Resources

### Tools
- **User Interviews:** Calendly, Zoom, Notion
- **Surveys:** Typeform, Google Forms
- **Analytics:** Mixpanel, Google Analytics
- **A/B Testing:** Custom implementation, Optimizely
- **Landing Pages:** Vercel, Webflow

### Templates
- **Experiment Template:** `/yc/EXPERIMENT_TEMPLATE.md`
- **User Interview Guide:** `/yc/USER_VALIDATION.md`
- **Pricing Survey:** `/yc/PRICING_VALIDATION.md`

---

## Success Metrics

### Experiment Success Criteria
- **Problem Validation:** >70% confirm problem
- **Solution Validation:** >80% satisfaction, >50% time saved
- **Customer Validation:** >60% willing to pay, >$50/mo average
- **Growth Validation:** >5% signup rate, >1.0 viral coefficient

### Process Success Criteria
- **Weekly Reviews:** 100% attendance, experiments documented
- **Monthly Reviews:** All hypotheses reviewed, status updated
- **Quarterly Reviews:** Strategy updated, pivots identified

---

## Next Steps

### Immediate (This Week)
1. [ ] Set up experiment tracking system
2. [ ] Schedule first weekly review
3. [ ] Identify first experiment (user interviews)
4. [ ] Create experiment template

### This Month
1. [ ] Run 4 experiments (one per week)
2. [ ] Document all learnings
3. [ ] Update hypothesis status
4. [ ] Review with advisors

### This Quarter
1. [ ] Establish experiment cadence
2. [ ] Validate core hypotheses
3. [ ] Identify pivot needs
4. [ ] Update strategy based on learnings

---

**Last Updated:** 2024-01-XX  
**Next Review:** [Date]

---

**Next:** See `/yc/HYPOTHESES.md` for hypothesis list and `/yc/EXPERIMENT_TEMPLATE.md` for experiment format.